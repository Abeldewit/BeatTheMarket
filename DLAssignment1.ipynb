{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7n4Sm6iIYQwK"
   },
   "source": [
    "# Deep Learning\n",
    "## Assignment 1 - Beat the market\n",
    "### Abel de Wit & Malin Hjärtström\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BqPj-NbDcnZp",
    "outputId": "4d9038ed-3e10-44da-b298-a539fb0d47d2",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Getting the data (commented for local use)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1ixezF29RbNx",
    "outputId": "ba5e021e-7051-4920-87ae-86fcc15a2919",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "1fILV-UnUnx-",
    "outputId": "55f5ca54-2a7c-4169-a68a-1da326d08514",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "info_data = pd.read_csv(\"data/info.txt\", sep='\\s+')\n",
    "market_analysis = pd.read_csv(\"data/market_analysis.txt\", sep='\\s+')\n",
    "market_segments = pd.read_csv(\"data/market_segments.txt\", sep='\\s+')\n",
    "stock_prices = pd.read_csv(\"data/stock_prices.txt\", sep='\\s+')\n",
    "\n",
    "# Do something with all our data so we can feed it to the NN\n",
    "dataframe = info_data\n",
    "\n",
    "# 'One hot encoding' the segments\n",
    "dataframe[\"IT\"] = dataframe['company'].apply(lambda x: 0 if x == 1 else 1)\n",
    "dataframe[\"BIO\"] = dataframe['company'].apply(lambda x: 1 if x == 1 else 0)\n",
    "#dataframe[\"trend\"] = market_analysis['trend']\n",
    "dataframe[\"stock-price\"] = stock_prices['stock-price']\n",
    "\n",
    "# Setting the indexes as the date\n",
    "dataframe.set_index(['year', 'day'], inplace=True)\n",
    "\n",
    "\n",
    "# For now we dont use some data\n",
    "# del dataframe['sentiment']\n",
    "# del dataframe['m1']\n",
    "# del dataframe['m2']\n",
    "# del dataframe['m3']\n",
    "# del dataframe['m4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now we split into companies\n",
    "\n",
    "company_0 = dataframe[dataframe['company'] == 0]\n",
    "company_1 = dataframe[dataframe['company'] == 1]\n",
    "company_2 = dataframe[dataframe['company'] == 2]\n",
    "\n",
    "# Let's see how their stocks are doing\n",
    "\n",
    "company_0.plot(y='stock-price').set_title('Company 0')\n",
    "company_1.plot(y='stock-price').set_title('Company 1')\n",
    "company_2.plot(y='stock-price').set_title('Company 2')\n",
    "\n",
    "del company_0['company']\n",
    "del company_0['quarter']\n",
    "del company_1['company']\n",
    "del company_1['quarter']\n",
    "del company_2['company']\n",
    "del company_2['quarter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict wether the stock goes up or not, so we have to change the stock price values in such a way that it is binary.\n",
    "\n",
    "`if stock-price-today - stock-price-yesterday > 0 then 1, else 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abel/anaconda3/envs/BeatTheMarket/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>expert1</th>\n",
       "      <th>expert2</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>IT</th>\n",
       "      <th>BIO</th>\n",
       "      <th>stock-price-binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1824</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6912</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.6</td>\n",
       "      <td>8928</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>5635</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">2019</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4444</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5901</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>352</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>5765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          expert1  expert2  sentiment   m1    m2   m3  m4  IT  BIO  \\\n",
       "year day                                                             \n",
       "2017 3          0        0         10  6.3  1824 -1.0   0   1    0   \n",
       "     4          0        1         10  5.1  6912 -0.9   0   1    0   \n",
       "     5          0        1         10  6.6  8928  0.3   0   1    0   \n",
       "     6          0        1         10  7.8  6924  0.0   0   1    0   \n",
       "     9          0        1         10 -0.9  5635  0.9   0   1    0   \n",
       "...           ...      ...        ...  ...   ...  ...  ..  ..  ...   \n",
       "2019 175        1        0          4  7.8  4444 -0.9   0   1    0   \n",
       "     176        0        0          5  6.8  5901 -0.7   0   1    0   \n",
       "     177        0        0          4  8.1  1631  0.0   0   1    0   \n",
       "     178        0        0          5  4.3   352 -0.9   0   1    0   \n",
       "     179        0        1          5 -1.2  5765  0.1   0   1    0   \n",
       "\n",
       "          stock-price-binary  \n",
       "year day                      \n",
       "2017 3                     0  \n",
       "     4                     0  \n",
       "     5                     0  \n",
       "     6                     0  \n",
       "     9                     0  \n",
       "...                      ...  \n",
       "2019 175                   0  \n",
       "     176                   0  \n",
       "     177                   0  \n",
       "     178                   0  \n",
       "     179                   1  \n",
       "\n",
       "[626 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "company_0['stock-price-binary'] = np.where(company_0['stock-price'] > company_0['stock-price'].shift(), 1, 0)\n",
    "del company_0['stock-price']\n",
    "company_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company 1\n",
    "\n",
    "So now we have the data in a nice table, split into seperate companies, we can do some machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626, 9)\n",
      "(626,)\n"
     ]
    }
   ],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_0 = scaler.fit_transform(company_0)\n",
    "scaled_0 = pd.DataFrame(data=scaled_0, columns=company_0.columns)\n",
    "\n",
    "X = scaled_0.loc[:, scaled_0.columns != 'stock-price-binary']\n",
    "y = scaled_0['stock-price-binary']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Now we split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                640       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,169\n",
      "Trainable params: 1,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 500 samples, validate on 126 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 483us/step - loss: 0.6633 - accuracy: 0.6200 - val_loss: 0.6195 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.6254 - accuracy: 0.6680 - val_loss: 0.5787 - val_accuracy: 0.6984\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.5943 - accuracy: 0.6580 - val_loss: 0.5448 - val_accuracy: 0.7063\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 51us/step - loss: 0.5698 - accuracy: 0.6860 - val_loss: 0.5105 - val_accuracy: 0.7698\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 67us/step - loss: 0.5401 - accuracy: 0.7420 - val_loss: 0.4774 - val_accuracy: 0.8651\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 77us/step - loss: 0.5101 - accuracy: 0.7780 - val_loss: 0.4448 - val_accuracy: 0.8889\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 60us/step - loss: 0.4828 - accuracy: 0.8200 - val_loss: 0.4113 - val_accuracy: 0.8968\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 50us/step - loss: 0.4505 - accuracy: 0.8280 - val_loss: 0.3762 - val_accuracy: 0.8968\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 55us/step - loss: 0.4291 - accuracy: 0.8400 - val_loss: 0.3527 - val_accuracy: 0.8730\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 57us/step - loss: 0.4036 - accuracy: 0.8300 - val_loss: 0.3332 - val_accuracy: 0.8968\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 54us/step - loss: 0.3904 - accuracy: 0.8400 - val_loss: 0.3171 - val_accuracy: 0.8889\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 50us/step - loss: 0.3774 - accuracy: 0.8340 - val_loss: 0.3066 - val_accuracy: 0.8968\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 52us/step - loss: 0.3729 - accuracy: 0.8360 - val_loss: 0.2961 - val_accuracy: 0.8968\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.3549 - accuracy: 0.8560 - val_loss: 0.2878 - val_accuracy: 0.8968\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.3583 - accuracy: 0.8480 - val_loss: 0.2808 - val_accuracy: 0.8810\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 51us/step - loss: 0.3497 - accuracy: 0.8520 - val_loss: 0.2760 - val_accuracy: 0.8810\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 54us/step - loss: 0.3371 - accuracy: 0.8480 - val_loss: 0.2709 - val_accuracy: 0.8810\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.3565 - accuracy: 0.8540 - val_loss: 0.2669 - val_accuracy: 0.8810\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 47us/step - loss: 0.3293 - accuracy: 0.8600 - val_loss: 0.2642 - val_accuracy: 0.8968\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 53us/step - loss: 0.3308 - accuracy: 0.8640 - val_loss: 0.2600 - val_accuracy: 0.8968\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 54us/step - loss: 0.3404 - accuracy: 0.8600 - val_loss: 0.2577 - val_accuracy: 0.8889\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 54us/step - loss: 0.3202 - accuracy: 0.8640 - val_loss: 0.2556 - val_accuracy: 0.8968\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 63us/step - loss: 0.3212 - accuracy: 0.8680 - val_loss: 0.2535 - val_accuracy: 0.8968\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.87 - 0s 48us/step - loss: 0.3193 - accuracy: 0.8640 - val_loss: 0.2526 - val_accuracy: 0.8889\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.3213 - accuracy: 0.8540 - val_loss: 0.2500 - val_accuracy: 0.8968\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 47us/step - loss: 0.3165 - accuracy: 0.8680 - val_loss: 0.2487 - val_accuracy: 0.8968\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 58us/step - loss: 0.3263 - accuracy: 0.8620 - val_loss: 0.2482 - val_accuracy: 0.8889\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 58us/step - loss: 0.3148 - accuracy: 0.8640 - val_loss: 0.2474 - val_accuracy: 0.8889\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 52us/step - loss: 0.3131 - accuracy: 0.8840 - val_loss: 0.2468 - val_accuracy: 0.8889\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.3050 - accuracy: 0.8740 - val_loss: 0.2457 - val_accuracy: 0.8889\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.3019 - accuracy: 0.8860 - val_loss: 0.2447 - val_accuracy: 0.8889\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 47us/step - loss: 0.3182 - accuracy: 0.8680 - val_loss: 0.2443 - val_accuracy: 0.8889\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.3061 - accuracy: 0.8760 - val_loss: 0.2438 - val_accuracy: 0.8889\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.3031 - accuracy: 0.8740 - val_loss: 0.2431 - val_accuracy: 0.8889\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.3157 - accuracy: 0.8660 - val_loss: 0.2424 - val_accuracy: 0.8889\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.3117 - accuracy: 0.8680 - val_loss: 0.2423 - val_accuracy: 0.8889\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.3107 - accuracy: 0.8740 - val_loss: 0.2422 - val_accuracy: 0.8889\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.3106 - accuracy: 0.8680 - val_loss: 0.2424 - val_accuracy: 0.8889\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.3190 - accuracy: 0.8600 - val_loss: 0.2421 - val_accuracy: 0.8889\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.3128 - accuracy: 0.8700 - val_loss: 0.2421 - val_accuracy: 0.8889\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 35us/step - loss: 0.3073 - accuracy: 0.8740 - val_loss: 0.2426 - val_accuracy: 0.8968\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.3114 - accuracy: 0.8700 - val_loss: 0.2427 - val_accuracy: 0.8968\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.3030 - accuracy: 0.8820 - val_loss: 0.2422 - val_accuracy: 0.8968\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.3071 - accuracy: 0.8660 - val_loss: 0.2427 - val_accuracy: 0.8889\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 47us/step - loss: 0.2968 - accuracy: 0.8700 - val_loss: 0.2420 - val_accuracy: 0.8889\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.3097 - accuracy: 0.8800 - val_loss: 0.2424 - val_accuracy: 0.8968\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.2956 - accuracy: 0.8740 - val_loss: 0.2424 - val_accuracy: 0.8968\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2992 - accuracy: 0.8860 - val_loss: 0.2422 - val_accuracy: 0.8968\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.3024 - accuracy: 0.8720 - val_loss: 0.2423 - val_accuracy: 0.8968\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.3008 - accuracy: 0.8820 - val_loss: 0.2422 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.3078 - accuracy: 0.8660 - val_loss: 0.2433 - val_accuracy: 0.8968\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2991 - accuracy: 0.8680 - val_loss: 0.2436 - val_accuracy: 0.8968\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.3121 - accuracy: 0.8680 - val_loss: 0.2435 - val_accuracy: 0.8968\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2948 - accuracy: 0.8780 - val_loss: 0.2443 - val_accuracy: 0.8810\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.3063 - accuracy: 0.8740 - val_loss: 0.2436 - val_accuracy: 0.8968\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2935 - accuracy: 0.8820 - val_loss: 0.2448 - val_accuracy: 0.8968\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2988 - accuracy: 0.8740 - val_loss: 0.2437 - val_accuracy: 0.8968\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.2949 - accuracy: 0.8740 - val_loss: 0.2443 - val_accuracy: 0.8968\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2983 - accuracy: 0.8740 - val_loss: 0.2442 - val_accuracy: 0.8968\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2968 - accuracy: 0.8800 - val_loss: 0.2448 - val_accuracy: 0.8810\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.2842 - accuracy: 0.8800 - val_loss: 0.2439 - val_accuracy: 0.8968\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.2902 - accuracy: 0.8780 - val_loss: 0.2437 - val_accuracy: 0.8889\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.2943 - accuracy: 0.8820 - val_loss: 0.2418 - val_accuracy: 0.8968\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2951 - accuracy: 0.8760 - val_loss: 0.2435 - val_accuracy: 0.8968\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2978 - accuracy: 0.8680 - val_loss: 0.2443 - val_accuracy: 0.8968\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2884 - accuracy: 0.8820 - val_loss: 0.2430 - val_accuracy: 0.8968\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2957 - accuracy: 0.8760 - val_loss: 0.2425 - val_accuracy: 0.8889\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.2961 - accuracy: 0.8880 - val_loss: 0.2430 - val_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2908 - accuracy: 0.8820 - val_loss: 0.2451 - val_accuracy: 0.8889\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2817 - accuracy: 0.8880 - val_loss: 0.2434 - val_accuracy: 0.8968\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2961 - accuracy: 0.8780 - val_loss: 0.2444 - val_accuracy: 0.9048\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.2965 - accuracy: 0.8800 - val_loss: 0.2456 - val_accuracy: 0.8889\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.2855 - accuracy: 0.8820 - val_loss: 0.2442 - val_accuracy: 0.8968\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2870 - accuracy: 0.8860 - val_loss: 0.2448 - val_accuracy: 0.8968\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2821 - accuracy: 0.8760 - val_loss: 0.2430 - val_accuracy: 0.8968\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2931 - accuracy: 0.8860 - val_loss: 0.2443 - val_accuracy: 0.8968\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2922 - accuracy: 0.8840 - val_loss: 0.2428 - val_accuracy: 0.8968\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.2896 - accuracy: 0.8860 - val_loss: 0.2434 - val_accuracy: 0.8889\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2805 - accuracy: 0.8900 - val_loss: 0.2446 - val_accuracy: 0.9048\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.2864 - accuracy: 0.8860 - val_loss: 0.2455 - val_accuracy: 0.8968\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2820 - accuracy: 0.8880 - val_loss: 0.2446 - val_accuracy: 0.8968\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2824 - accuracy: 0.8820 - val_loss: 0.2452 - val_accuracy: 0.8889\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2860 - accuracy: 0.8840 - val_loss: 0.2430 - val_accuracy: 0.8968\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2844 - accuracy: 0.8880 - val_loss: 0.2438 - val_accuracy: 0.8889\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.2833 - accuracy: 0.8960 - val_loss: 0.2432 - val_accuracy: 0.9048\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2844 - accuracy: 0.8920 - val_loss: 0.2444 - val_accuracy: 0.8889\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2785 - accuracy: 0.8920 - val_loss: 0.2457 - val_accuracy: 0.8968\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.2787 - accuracy: 0.8880 - val_loss: 0.2431 - val_accuracy: 0.8889\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2765 - accuracy: 0.8840 - val_loss: 0.2427 - val_accuracy: 0.8968\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.2723 - accuracy: 0.8820 - val_loss: 0.2418 - val_accuracy: 0.8968\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.2770 - accuracy: 0.8920 - val_loss: 0.2418 - val_accuracy: 0.8889\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.2888 - accuracy: 0.8880 - val_loss: 0.2437 - val_accuracy: 0.9048\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.2813 - accuracy: 0.8780 - val_loss: 0.2437 - val_accuracy: 0.9048\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 52us/step - loss: 0.2788 - accuracy: 0.8900 - val_loss: 0.2452 - val_accuracy: 0.9048\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 57us/step - loss: 0.2785 - accuracy: 0.8900 - val_loss: 0.2432 - val_accuracy: 0.9048\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 59us/step - loss: 0.2801 - accuracy: 0.8900 - val_loss: 0.2430 - val_accuracy: 0.9048\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 61us/step - loss: 0.2857 - accuracy: 0.8760 - val_loss: 0.2450 - val_accuracy: 0.9048\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.2849 - accuracy: 0.8860 - val_loss: 0.2461 - val_accuracy: 0.9127\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2736 - accuracy: 0.8960 - val_loss: 0.2433 - val_accuracy: 0.9048\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2728 - accuracy: 0.8920 - val_loss: 0.2455 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x138d543d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime, os\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "# Create a model.\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=9, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, input_dim=9, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    \"fit\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=100, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[tensorboard_callback],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 9736), started 12:40:24 ago. (Use '!kill 9736' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-412bff478953f357\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-412bff478953f357\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6007;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DLAssignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
